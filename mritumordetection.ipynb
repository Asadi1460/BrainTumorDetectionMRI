{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7097852,"sourceType":"datasetVersion","datasetId":4091068}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# $\\color{red}{\\text{DL Final Project: MRI Tumor Detection}}$","metadata":{}},{"cell_type":"markdown","source":"# NEW","metadata":{}},{"cell_type":"markdown","source":"<h1 style=\"background-color:DodgerBlue;\">\nNecessary imports and Load dataset\n</h1>\n\n","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries\nimport os\nimport shutil\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import BatchNormalization, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import ResNet50","metadata":{"execution":{"iopub.status.busy":"2023-12-15T09:06:36.839932Z","iopub.execute_input":"2023-12-15T09:06:36.840346Z","iopub.status.idle":"2023-12-15T09:06:57.214353Z","shell.execute_reply.started":"2023-12-15T09:06:36.840314Z","shell.execute_reply":"2023-12-15T09:06:57.213269Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<h2 style=\"background-color:DodgerBlue;\">\nLoad dataset, review, and split to train and test\n</h2>\n\n","metadata":{}},{"cell_type":"code","source":"# Set random seed for reproducibility\nseed = 42\nnp.random.seed(seed)\ntf.random.set_seed(seed)\n\n# Function to count images in a folder\ndef count_images(folder_path, prefix):\n    count = 0\n    for file_name in os.listdir(folder_path):\n        if file_name.startswith(prefix):\n            count += 1\n    return count\n\n# Specify the directory path\ndir_path = '/kaggle/input/mritumor/Data'\n\n# categories = ['Glioma Tumor', 'Meningioma Tumor', 'Normal', 'Pituitary Tumor']\n\n# Find categories (folders) in the specified directory\ncategories = [folder_name for folder_name in os.listdir(dir_path) if os.path.isdir(os.path.join(dir_path, folder_name))]\n\n# Initialize counts for each category\ncategory_counts = {category: 0 for category in categories}\n\n# Iterate through the folders and count images\nfor category in categories:\n    category_path = os.path.join(dir_path, category)\n    category_counts[category] = count_images(category_path, '')\n\n# Print the counts for each category\nfor category, count in category_counts.items():\n    print(f'Number of images in {category}: {count}')","metadata":{"execution":{"iopub.status.busy":"2023-12-15T09:09:12.147434Z","iopub.execute_input":"2023-12-15T09:09:12.148460Z","iopub.status.idle":"2023-12-15T09:09:12.760409Z","shell.execute_reply.started":"2023-12-15T09:09:12.148423Z","shell.execute_reply":"2023-12-15T09:09:12.759477Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Number of images in pituitary_tumor: 844\nNumber of images in meningioma_tumor: 913\nNumber of images in glioma_tumor: 901\nNumber of images in normal: 438\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# ... (previous code)\n\n# Split the data into training, validation, and testing sets\ntrain_files, test_files, train_labels, test_labels = train_test_split(\n    file_paths, labels, test_size=test_percent, random_state=seed, stratify=labels\n)\n\ntrain_files, val_files, train_labels, val_labels = train_test_split(\n    train_files, train_labels, test_size=val_percent/(1-train_percent), random_state=seed, stratify=train_labels\n)\n\n# Create generators for training, validation, and testing sets\nbatch_size = 32  # Adjust as needed\nimg_size = (150, 150)  # Adjust as needed\n\ntrain_gen = datagen.flow(\n    x=train_files,\n    y=train_labels,\n    target_size=img_size,\n    class_mode='categorical',\n    color_mode='rgb',\n    shuffle=True,\n    batch_size=batch_size\n)\n\nval_gen = datagen.flow(\n    x=val_files,\n    y=val_labels,\n    target_size=img_size,\n    class_mode='categorical',\n    color_mode='rgb',\n    shuffle=True,\n    batch_size=batch_size\n)\n\ntest_gen = datagen.flow(\n    x=test_files,\n    y=test_labels,\n    target_size=img_size,\n    class_mode='categorical',\n    color_mode='rgb',\n    shuffle=False,\n    batch_size=batch_size\n)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T09:14:53.758106Z","iopub.execute_input":"2023-12-15T09:14:53.758829Z","iopub.status.idle":"2023-12-15T09:14:53.815532Z","shell.execute_reply.started":"2023-12-15T09:14:53.758793Z","shell.execute_reply":"2023-12-15T09:14:53.814305Z"},"trusted":true},"execution_count":8,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m  \u001b[38;5;66;03m# Adjust as needed\u001b[39;00m\n\u001b[1;32m     17\u001b[0m img_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m150\u001b[39m)  \u001b[38;5;66;03m# Adjust as needed\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m train_gen \u001b[38;5;241m=\u001b[39m \u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrgb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m val_gen \u001b[38;5;241m=\u001b[39m datagen\u001b[38;5;241m.\u001b[39mflow(\n\u001b[1;32m     30\u001b[0m     x\u001b[38;5;241m=\u001b[39mval_files,\n\u001b[1;32m     31\u001b[0m     y\u001b[38;5;241m=\u001b[39mval_labels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size\n\u001b[1;32m     37\u001b[0m )\n\u001b[1;32m     39\u001b[0m test_gen \u001b[38;5;241m=\u001b[39m datagen\u001b[38;5;241m.\u001b[39mflow(\n\u001b[1;32m     40\u001b[0m     x\u001b[38;5;241m=\u001b[39mtest_files,\n\u001b[1;32m     41\u001b[0m     y\u001b[38;5;241m=\u001b[39mtest_labels,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size\n\u001b[1;32m     47\u001b[0m )\n","\u001b[0;31mTypeError\u001b[0m: ImageDataGenerator.flow() got an unexpected keyword argument 'target_size'"],"ename":"TypeError","evalue":"ImageDataGenerator.flow() got an unexpected keyword argument 'target_size'","output_type":"error"}]},{"cell_type":"code","source":"# Specify the percentage of data for training, validation, and testing\ntrain_percent = 0.8  # 80% for training\nval_percent = 0.1    # 10% for validation\ntest_percent = 0.1   # 10% for testing\n\n# Create empty lists to store file paths and corresponding labels\nfile_paths = []\nlabels = []\n\n# Iterate through the folders and collect file paths and labels\nfor category in categories:\n    category_path = os.path.join(dir_path, category)\n    image_files = [file_name for file_name in os.listdir(category_path) if file_name.endswith('.jpg')]\n    file_paths.extend([os.path.join(category_path, file_name) for file_name in image_files])\n    labels.extend([category] * len(image_files))\n\n# Split the data into training, validation, and testing sets\ntrain_files, test_files, train_labels, test_labels = train_test_split(\n    file_paths, labels, test_size=test_percent, random_state=seed, stratify=labels\n)\n\ntrain_files, val_files, train_labels, val_labels = train_test_split(\n    train_files, train_labels, test_size=val_percent/(1-train_percent), random_state=seed, stratify=train_labels\n)\n\n# Print the number of samples in each set\nprint(f'Number of training samples: {len(train_files)}')\nprint(f'Number of validation samples: {len(val_files)}')\nprint(f'Number of testing samples: {len(test_files)}')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-15T09:09:12.761999Z","iopub.execute_input":"2023-12-15T09:09:12.762341Z","iopub.status.idle":"2023-12-15T09:09:12.806556Z","shell.execute_reply.started":"2023-12-15T09:09:12.762315Z","shell.execute_reply":"2023-12-15T09:09:12.805584Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Number of training samples: 1392\nNumber of validation samples: 1394\nNumber of testing samples: 310\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Set up output directories\n# output_dir = '/kaggle/working/dataset'\n# test_size = 0.2\n# train_dir = os.path.join(output_dir, 'train')\n# test_dir = os.path.join(output_dir, 'test')\n# val_dir = os.path.join(output_dir, 'val')\n\n# os.makedirs(train_dir, exist_ok=True)\n# os.makedirs(test_dir, exist_ok=True)\n# os.makedirs(val_dir, exist_ok=True)\n\n# # Split images into train, test, and val sets\n# for category in categories:\n#     category_path = os.path.join(dir_path, category)\n#     images = [file_name for file_name in os.listdir(category_path) if file_name.endswith('.jpg')]\n#     train_images, test_val_images = train_test_split(images, test_size=test_size, random_state=seed)\n#     test_images, val_images = train_test_split(test_val_images, test_size=0.5, random_state=seed)\n\n#     for image in train_images:\n#         src_path = os.path.join(category_path, image)\n#         dest_path = os.path.join(train_dir, category, image)\n#         os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n#         shutil.copyfile(src_path, dest_path)\n\n#     for image in test_images:\n#         src_path = os.path.join(category_path, image)\n#         dest_path = os.path.join(test_dir, category, image)\n#         os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n#         shutil.copyfile(src_path, dest_path)\n\n#     for image in val_images:\n#         src_path = os.path.join(category_path, image)\n#         dest_path = os.path.join(val_dir, category, image)\n#         os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n#         shutil.copyfile(src_path, dest_path)\n\n# # Print the number of images in each set\n# print(f'\\nNumber of training images: {int(sum(category_counts.values()) * (1 - test_size))}')\n# print(f'Number of testing images: {int(sum(category_counts.values()) * test_size)}')\n# print(f'Number of validation images: {int(sum(category_counts.values()) * test_size * 0.5)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_images(images):\n    preprocessed_images = []\n    for i in range(len(images)):\n        image = images[i]\n        \n        # Convert the BGR image to LAB color space\n        img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n#         # Split the LAB image into L, A, and B channels\n        r, g, b = cv2.split(img)\n#         print(r)\n    \n        # Ensure the channels have the correct data type (8-bit unsigned)\n        r = r.astype(np.uint8)\n        g = g.astype(np.uint8)\n        b = b.astype(np.uint8)\n        \n        # Apply CLAHE to each channel separately\n        clahe = cv2.createCLAHE(clipLimit=6.0, tileGridSize=(8,8))\n        r = clahe.apply(r)\n        g = clahe.apply(g)\n        b = clahe.apply(b)\n\n        # Merge the enhanced RGB channels \n        img_output = cv2.merge([r, g, b])\n        \n       \n        # Convert the LAB image back to BGR color space\n        preprocessed_image = cv2.cvtColor(img_output, cv2.COLOR_RGB2BGR)\n        \n        preprocessed_images.append(preprocessed_image)\n            \n    return np.array(preprocessed_images)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T09:09:12.807747Z","iopub.execute_input":"2023-12-15T09:09:12.808038Z","iopub.status.idle":"2023-12-15T09:09:12.816875Z","shell.execute_reply.started":"2023-12-15T09:09:12.808006Z","shell.execute_reply":"2023-12-15T09:09:12.815824Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Constants\nimg_size = (256, 256)\nbatch_size = 32\nimg_shape = (img_size[0], img_size[1], 3)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T09:09:12.819272Z","iopub.execute_input":"2023-12-15T09:09:12.819944Z","iopub.status.idle":"2023-12-15T09:09:12.833806Z","shell.execute_reply.started":"2023-12-15T09:09:12.819903Z","shell.execute_reply":"2023-12-15T09:09:12.833067Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# ImageDataGenerator with data augmentation\ntr_gen = ImageDataGenerator(\n    rescale=1./255.0,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest',\n#     preprocessing_function=preprocess_images  # Custom preprocessing function using a median filter\n)\n\n# Image data generator for loading and augmenting images\ntrain_gen = tr_gen.flow_from_directory(\n    train_dir, \n    target_size=img_size, \n    class_mode='categorical',\n    color_mode='rgb', \n    shuffle=True, \n    batch_size=batch_size\n)\n\n# Create ImageDataGenerator without data augmentation\ndatagen = ImageDataGenerator(\n    rescale=1./255.0,  # Rescale pixel values to the range [0, 1]\n)\n\n\n# Validation data generator\nvalid_gen = datagen.flow_from_directory(\n    val_dir,\n    target_size=img_size,\n    class_mode='categorical',\n    color_mode='rgb',\n    shuffle=True,\n    batch_size=batch_size\n)\n\n# Test data generator\ntest_gen = datagen.flow_from_directory(\n    test_dir,\n    target_size=img_size,\n    class_mode='categorical',\n    color_mode='rgb',\n    shuffle=False,\n    batch_size=batch_size\n)","metadata":{"execution":{"iopub.status.busy":"2023-12-15T09:09:21.412964Z","iopub.execute_input":"2023-12-15T09:09:21.413804Z","iopub.status.idle":"2023-12-15T09:09:22.144713Z","shell.execute_reply.started":"2023-12-15T09:09:21.413771Z","shell.execute_reply":"2023-12-15T09:09:22.143443Z"},"trusted":true},"execution_count":6,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 16\u001b[0m\n\u001b[1;32m      2\u001b[0m tr_gen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[1;32m      3\u001b[0m     rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m,\n\u001b[1;32m      4\u001b[0m     rotation_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#     preprocessing_function=preprocess_images  # Custom preprocessing function using a median filter\u001b[39;00m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Image data generator for loading and augmenting images\u001b[39;00m\n\u001b[1;32m     15\u001b[0m train_gen \u001b[38;5;241m=\u001b[39m tr_gen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mtrain_dir\u001b[49m, \n\u001b[1;32m     17\u001b[0m     target_size\u001b[38;5;241m=\u001b[39mimg_size, \n\u001b[1;32m     18\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m     color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     20\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m     21\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Create ImageDataGenerator without data augmentation\u001b[39;00m\n\u001b[1;32m     25\u001b[0m datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[1;32m     26\u001b[0m     rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255.0\u001b[39m,  \u001b[38;5;66;03m# Rescale pixel values to the range [0, 1]\u001b[39;00m\n\u001b[1;32m     27\u001b[0m )\n","\u001b[0;31mNameError\u001b[0m: name 'train_dir' is not defined"],"ename":"NameError","evalue":"name 'train_dir' is not defined","output_type":"error"}]},{"cell_type":"code","source":"# Retrieve a batch of images and labels from the generator\nimages, labels = next(train_gen)\nnum_samples = len(images)\n\n# Plot the images with class names\nplt.figure(figsize=(20, 20))\nfor i in range(min(16, num_samples)):\n    plt.subplot(4, 4, i + 1)\n    # Explicitly cast to float32 before normalization\n    image = images[i].astype('float32') / 255.0  \n\n    plt.imshow(image)\n    class_index = int(labels[i])\n    class_name = classes[class_index]  # Assuming you have defined 'classes' based on your dataset\n    plt.title(class_name, color='blue', fontsize=12)\n    plt.axis('off')\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"background-color:red;\">\n<!-- <div style=\"direction:rtl\">  </div> -->\nMaking Model \n</h2>\n\n","metadata":{}},{"cell_type":"code","source":"# Model\nbase_model = ResNet50(include_top=False, weights='imagenet', input_shape=img_shape, pooling='max')\nbase_model.trainable = False\n\nnum_classes = len(categories)\n\nmodel = Sequential([\n    base_model,\n    BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001),\n    Dense(256, kernel_regularizer=tf.keras.regularizers.l2(l=0.016),\n          activity_regularizer=tf.keras.regularizers.l1(0.006),\n          bias_regularizer=tf.keras.regularizers.l1(0.006), activation='relu'),\n    Dropout(rate=0.4, seed=seed),\n    Dense(num_classes, activation='softmax')\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"background-color:red;\">\n<!-- <div style=\"direction:rtl\">  </div> -->\nCompile and run the Model \n</h2>\n\n","metadata":{}},{"cell_type":"code","source":"model.compile(Adamax(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n\n# Model summary\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model training\nhistory = model.fit(train_gen, validation_data=valid_gen, epochs=50, verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h2 style=\"background-color:Violet;\">\n<!-- <div style=\"direction:rtl\">  </div> -->\nEvaluate model\n </h2>\n\n","metadata":{}},{"cell_type":"code","source":"# Model evaluation\ntrain_score = model.evaluate(train_gen, steps=len(train_gen))\nval_score = model.evaluate(valid_gen, steps=len(valid_gen))\ntest_score = model.evaluate(test_gen, steps=len(test_gen))\n\nprint(f'Train loss = {train_score[0]}')\nprint(f'Train Accuracy = {train_score[1]}')\nprint(f'Validation loss = {val_score[0]}')\nprint(f'Validation Accuracy = {val_score[1]}')\nprint(f'Test loss = {test_score[0]}')\nprint(f'Test Accuracy = {test_score[1]}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model predictions\npred_probs = model.predict(test_gen)\npredicted_classes = np.argmax(pred_probs, axis=1)\n\n# Get true labels from the generator\ntrue_classes = test_gen.classes\n\n# Confusion matrix\nconfusion = confusion_matrix(true_classes, predicted_classes)\n\n# Display confusion matrix\ndisp = ConfusionMatrixDisplay(confusion_matrix=confusion, display_labels=test_gen.class_indices)\ndisp.plot(cmap='Blues', values_format='d')\n\n# Classification report\nclassification_rep = classification_report(true_classes, predicted_classes, target_names=categories)\nprint(\"\\nClassification Report:\")\nprint(classification_rep)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting accuracy and loss over epochs\nplt.figure(figsize=(12, 4))\n\n# Plot training & validation accuracy values\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Validation'], loc='upper left')\n\n# Plot training & validation loss values\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Validation'], loc='upper left')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}